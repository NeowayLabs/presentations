Real Life Kubernetes
Neoway Study Case
18 Apr 2016
Tags: DevOps, k8s, microservices, cluster orchestration

Fabio Favero Henkes
Lead Developer - Prevention Team, Neoway
fabio.favero@neoway.com.br
http://www.neoway.com.br
@ffhenkes

Tiago CÃ©sar Katcipis
Metaphores enthusiast / Bug Factory - Datapirates Team, Neoway
tiago.katcipis@neoway.com.br
https://github.com/katcipis
@tiagokatcipis


* Why should you care ?


* Fancy some Microservices ?

- Organized around Business Capabilities
- Smart endpoints and dumb pipes (no complex stateful protocols)
- Decentralized Governance
- Decentralized Data Management
- Cool way to apply good and old divide and conquer
- Service orientation done right


* Microservices tradeoff, no free lunch for you

* For each service you need

- Build an deployable artifact
- Deploy your artifact
- Keep your service running
- Scale (better if it is autoscale)
- Load balance it (if it exposes an API, which usually is the case)
- Expose it to other services that depends on it (service discovery)
- Health check (check if it is actually working, not just running)
- With one service you can survive doing manual stuff
- With microservices it is automation or agonizing death :-)
.link http://martinfowler.com/bliki/MicroservicePrerequisites.html


* Cattle, not pets

- Treat nodes as cattle, not pets
- No manual configuration
- No node is "special" and needs individual care
- If it goes sick, just kill it
- If it dies, just add a new one
- They are just a pool or computational resources
- No need to know where each service is running
- Infrastructure as code is your friend
- Imagine trying to work with pets when you have 100 different services


* What we want ?

- A way to automate everything
- As little distance as possible between running on the dev machine and production
- Easy way to: configure, scale, service discovery, load balance, health check, rolling update, debug
- Adding new services must be easy (we are going to have a lot of them :-)
- No need to ssh/log into nodes (this should be an exception, not the norm)
- No snowflakes servers


* The Deployable artifact: Docker

- Self-contained (no hell of dependencies)
- Language agnostic way to package and run applications
- Closes the gap between environments (dev <-> staging <-> production)
- Solves pretty nicely the artifact problem
- But how to run 100 containers through 10 machines ?
- How to connect different containers with each other ?
- How to keep then running even on failures ?


* The Container Orchestrator: Kubernetes

- Scheduling
- Scaling
- Load Balance
- Health Check
- Service discovery


* Kubernetes why ?

- More than just using fleet
- Less than using Mesos/Mesosphere/Deis
- We wanted something more, but that doesn't was a PAAS
- Kubernetes is a CAAS (Container As A Service)
- Just what we wanted :-)
- Cool / Scalable way to extend (through REST API)
- Great community (Google + Red Hat as top contributors, not bad :-)


* Overview

.image ./img/kubernetes.png


* Pathfinder

- Concept
- Architecture
- Deploy
- AWS

* Pathfinder Architecture Overview

.image ./img/overview.png 490 581

* Pathfinder AWS Infrastructure

.image ./img/networking.png 667 811

* Pathfinder Autos Scaling

.image ./img/autoscaling.png
